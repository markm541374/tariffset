\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{\textbf{Using GPGO to find electricity tariffs that
induce optimal load profiles
}}
\author{}
\date{}
\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Scenario}

The premise is that I am an electricity supplier / distributor on the national grid
in the near future. I have a set of customer that draw power from the grid and
pay for this power according to a tariff that is linear in power but the gradient
may vary over time. I have the ability to set this tariff. I may also have a
set of power sources that I can use to supply power but I cannot control these
sufficiently to match demand so any imbalance must be purchased from or sold to other suppliers.I therefore wish to set the tariff so that demand is matched as closely as possible to my supply. This is possible if a significant
proportion of consumer devices have some autonomous capability and are able
to alter their actions in response to variation in the daily tariff so that their cost
of operation is minimized.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Agent specification}
Each customer has a number of devices which consume power. The load profile induced over time is well studied and predictable for the sum over a large number of consumers. Some recent research has been done into disaggregating power usage at the level of a single home into individual devices \cite{kolter2011redd} \cite{anderson2012blued}. \cite{kolter2011redd} Suggests modeling the system as a factorial hidden Markov model in which each device is a single hidden Markov model. At present almost all devices do not take account of electricity pricing and simply function directly when switched on by the owner, however this is not true under a smart-grid scenario. We classify all power consuming devices $d \in D$ which produce a load profile $p_{d}(t)$ as direct-use devices $d \in U$ if they are not influenced by price variations (lighting, cooking, entertainment systems) or intelligent agents $d \in A$ if they have access to the electricity price and are equipped to alter their behaviour accordingly (heating, cooling, washers, dryers) such that $A$ and $U$ are disjoint and their union is $D$. The power demand that must be met is therefore the sum of power used by direct-use devices and intelligent devices
\begin{equation}
P_{u} (t) = \sum_{d \in U} p_{d} (t)
\end{equation}


Some consumer devices will be able to alter their power use profile in order to
exploit price variations. Let $\theta$ be a parameter vector with sufficient information
to derive the instantaneous tariff at any time according to
\begin{equation}
\tau = f(t, \theta)
\end{equation}
where $f$ is some know function. Let each device with the ability to independently alter their profile in response to $\theta$ be defined as an agent $a \in A$.
Each agent has private information $\phi_{a} \in \Phi $ set by the user which constrains the
agent operation to behaviours that allow it to fulfil its function. It must chose a
schedule $s_{a} \in S_{a}$ from the set of all schedules that satisfy its constraints. Not all
choices of $s_{a}$ are equally good to the user so the agent also has a utility function
$u_{s} : S, \Phi \rightarrow v\qquad v \in \mathbb{R} $ which allows it to determine the value to the user of choosing a
particular action. If the power use induced under $s$ is given by $ p_{a} (s, t) $then the total cost of
electricity under that schedule is
\begin{equation}
u_{a}^{e} = \intop_{t} p(s_{a}, t) \tau(\theta, t) \mathrm{d}t
\end{equation}
The schedule chose by an intelligent agent will therefore be
\begin{equation}
s_{a} = \argmin _{s \in S_{a}} u_{a}^{e} + u_{a}^{s}
\end{equation}
The power used by all agents over time is therefore
\begin{equation}
P_{a}(t) = \sum_{a \in A} p (s_{a} , t)
\end{equation}

The power demand
by
\begin{equation}
\Delta P (t) = P_{a} (t) + P_{c} (t) - P_{G} (t)
\end{equation}
We wish to minimize this under some cost mapping i.e. integral of the 2-norm
\begin{equation}
y = G(\theta) = \intop_{t} P (t)^{2} \mathrm{d}t
\end{equation}
which is a multiple input single output function $G : \mathbb{R}^{N} \rightarrow \mathbb{R}$
Since $\phi, u$ may be any arbitrary values and arbitrarily complex functions for
each agent we must treat $G$ as a black box process which may be multi-modal.
We obviously cannot experiment on a real electricity network with a realistic
number of customers so we must use simulations. Since the total power use is
the sum of a large number of individual profiles each of which is determined by
an agent running an optimization routine we must treat this black box function
as expensive and therefore use appropriate optimization techniques for functions
that are expensive to evaluate.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{The simplest agent}
The most simple agent is a shift-able static load. Washers and dryers are an
example of this category. They will consume power in a fixed profile from the
start time until the end of their cycle of length T . The only scheduling variable
to be changed is the start time and the only constraint is the latest permissible
finish time $tf$ . The agent is considered to be initialized by the user at time
$t_{0}$ for which the utility of starting is zero and decreases linearly according to a
gradient parameter $\alpha$. The utility of scheduling is therefore
\begin{equation}
u{a} (s = t_{s} ) = −\alpha (t_{s} − t_{0} )\qquad S = [t_{0} , t_{f} − T )
\end{equation}
This makes the optimization a 1D search with in a finite region so relatively
simple to implement. The values of $\alpha, t_{0} , t_{f}$ and the load profile and duration
should be drawn from some distribution based on ownership and use of various
devices.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
 
\section{More complex agents}
It may be useful to implement various load profiles and non-linear utility functions. It is easy to imagine a device being set to “finish in time for $x$ but do not
run between $y$ and $z$ unless $w$”
Thermal loads
These are much more complex. The agents require to maintaining a temperature T as close as possible to some target for all the time they are operating
with a utility cost for deviation. This must be maintained despite thermal loss
to the environment using a heater/heatpump. The simplest reasonable model
is to consider a fixed thermal mass $cm$ with a binary power input $k_{1} \delta (on)$and
loss to the environment $k_{2} (T - T_{ext} )$. A suggested utility for deviation from
the target is asymmetric quadratic cost. For a reasonably simple case such as
this the optimal control input under a given tariff can be found using quadratic
solvers.
There is considerable scope for refinement in modelling thermal loads. The
heat pump power, thermal mass and insulation rating can all be investigated,
the external temperature is variable in geography and strongly linked to daily
weather conditions. considerable work could be done in putting together a good
predictive model of demand for a given population using surveys and observation
of the response.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Tariff specification}
One of the common electricity pricing schemes proposed for the smart grid is
time of use (TOC) pricing in which prices vary over time but are fixed and
communicated to consumers in advance. The method we propose is to communicate the information for an entire 24 hour period in advance of the start
of that period . This allows agent sufficient time to reschedule loads to the
optimum within operation constraints and simplifies the problem by making it
episodic.
A common proposal for TOU tariffs is to split the day into 48 half hour
periods with constant rates during those blocks. We will consider this method,
but we will also consider continuously varying tariffs defined by finite support
vectors such as Gaussian mixture models with varying size of support vector.
Various methods for real time control have been proposed. However these
are limited in effectiveness as they can only influence devices which have real
time flexibility in operation. Providing price information ahead of time opens an
entire set of devices up to influence by price variations. Methods to incentivize
agents to report back predicted so that purchase of power to balance excess in
advance can be more accurate. I see no obvious reason this cannot also be done
in conjunction with time of use pricing. \cite{ramchurn2011agent} propose a method for shifting
load by time of use pricing, but their method relies on agents being slow to
converge to the optimum in the prevention of new peaks forming. There seems
to be no reason for an individual agent not to learn faster to save more money
and if all agents were to do this the system would not function.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Plan}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{1st step}
The tariff will be a GMM with 8 support points (looping around). All $\sim 10^{3}$
agents in the system will have a 1 unit load for 1 hour and must finish by
the end of the day. The agent start time is drawn from a distribution with a
distinct peak in the middle of the day. The power supplies that I own provide a
flat profile equal to the average consumption at a constant cost. Excess supply
incurs a small quadratic cost. Excess demand incurs a larger quadratic cost.
This should be very easy to implement, the agents themselves provide an
obvious parallelization. I have python GPGO code already. With no apparent
reason to do otherwise I suppose I should use a Matern $ \frac{3}{2} $ kernel initially as it accommodates multiple lengthscales seems to be commonly used in literature. Considering what kernel should actually be used is probably something for later steps, I think there will be discontinuities as if there are two local minima the transition from one being deeper to the other will cause a number of agents to make a step change in their scheduling pattern. The prior is also debatable. If the pdf from which the agent start times are drawn is known
I could say my prior belief on the induced load is demand/supply and integrate
this under the cost function to find a prior on the output but this would only
really be tractable at this level, it probably wouldn't work for more complex
agents.
Once this seems to be working: variation of number of support points. is
there a good value to use? Switch to constant block tariff, how does it compare.
How does the variance in the result correspond to the number of agents? I think this will have similar characteristics to choosing the number of degrees of freedom in a model. Performance will improve sharply at first as sufficient DOF are obtained to move the bulk of agents away from peaks and towards troughs, beyond a certain value where the profile is broadly flat performance will be only small refinements and will improve much more gradually. It may also be capped by the number of agents, I think with an infinite number of agents and infinite degrees of freedom the profile could be flattened exactly, but for a finite number this will not be the case and there will be a point where it is the individual agents in the test set that are being optimised over rather than the agent distribution. Using multiple test sets and updating the GP using a mean and variance rather than an exact value should help with this.
What should I be using as a performance metric, ratio of cost to flat tariff? Could also
look at max/min ratio reduction or the shape of the load-duration curve rather than overall cost if the optimization is changed to have this as its objective. This somewhat depends on the exact details of how we are sourcing the electricity and how well the optimisation is working. If I own a large number of sources of various types and can meet all demand myself I might aim for max/min ratio so that I do not need to maintain extra facilities to cope with the peaks, if I am a smaller provider and need to buy on the wholesale market I might aim to reduce flatness to keep my expenditure on the wholesale market down.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Moving Further}
Realistic power profiles and start times. Make a thermal load agent and test that
under similar simple circumstances. Realistic thermal load parameters. This is replicating \cite{ramchurn2011agent}. Match load to a given supply profile rather than just flattening (tidal/wind/wave). This is new, I have seen schemes proposed that manage demand by sending command signals to cooperative consumers\cite{ramchurn2011agent2} , schemes that use price as a non-trivial control signal in real time and schemes that expose the agent to predicted wholesale prices ahead of time, but none that expose the agent to a calculated price ahead of time. This method therefore has both the opportunity to make greater savings that is available with prices published ahead of time and the flexibility to shape demand that is available from multiple degrees of freedom in control.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Even Further}
Combine consumer loads, static loads and thermal loads in realistic proportions to make a model of a real customer set and measure how much demand can be influenced and therefore how much money can be saved. This would be a demonstration that setting and publishing tariffs ahead of time is a useful technique and should therefore be implemented in reality. This would need some game-theory style calculations to show that a supplier switching to this system with the current non-smart consumer base would not lose money and that consumers would have an incentive to become smart if the system was implemented.
Moving focus away from the tariff setting somewhat: build models of populations with parameters that are affected by location/weather/timeofyear. Try to do inference on the distribution of agent parameters based on the response
to a tariff. Example: combining response with weather maps over several days I might be able to work out the geographical distribution of heating/cooling system powers and setpoints and so have a better model for demand prediction under weather variations in future. This is not clearly something that will benefit from GPGO, I think it would be something interesting to apply some other techniques to in the future, but easier to get started with than something completely different.

\bibliography{problem_spec.bib}{}
\bibliographystyle{plain}
\end{document}
